{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name : Chloe Evelley Thesman\n",
    "# Student ID Number : 101111044165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2076bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE - LECTURE HW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c44bf03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 1\n",
    "\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "318fb38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 391\n",
      "Number of columns: 11\n",
      "Columns in the dataset:\n",
      "['row_n', 'id', 'name', 'gender', 'species', 'birthday', 'personality', 'song', 'phrase', 'full_id', 'url']\n"
     ]
    }
   ],
   "source": [
    "# Question 2, Part 1\n",
    "\n",
    "# Load the dataset from the provided URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "villagers_data = pd.read_csv(url)\n",
    "\n",
    "# Print the number of rows and columns\n",
    "num_rows, num_columns = villagers_data.shape\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_columns}\")\n",
    "\n",
    "# Print the column names\n",
    "print(\"Columns in the dataset:\")\n",
    "print(villagers_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adf1d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2, Part 2\n",
    "# Observations\n",
    "# Observations, in the world of python, refers to the individual entries or data points found in the dataset. Each observation made usually corresponds to a single case, example, or record.\n",
    "# In this context, with the Animal Crossing villagers dataset, each observation would represent one specfic villager. Thus, the number of observations is essentially the number of rows in the dataset.\n",
    "\n",
    "# Variables\n",
    "# On the other hand, variables are the different attributes or characteristics that is being measured / observed. The number of variables is basically the number of columns present in the dataset.\n",
    "# For example, in this Animal Crossing villagers dataset,  variables could include traits / features / properties like the villager's name, species, personality type, birthday, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49fadf42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   row_n       id     name  gender    species birthday personality  \\\n",
      "0      2  admiral  Admiral    male       bird     1-27      cranky   \n",
      "1      3  agent-s  Agent S  female   squirrel      7-2       peppy   \n",
      "2      4    agnes    Agnes  female        pig     4-21        uchi   \n",
      "3      6       al       Al    male    gorilla    10-18        lazy   \n",
      "4      7  alfonso  Alfonso    male  alligator      6-9        lazy   \n",
      "\n",
      "          song    phrase           full_id  \\\n",
      "0   Steep Hill   aye aye  villager-admiral   \n",
      "1      DJ K.K.  sidekick  villager-agent-s   \n",
      "2   K.K. House   snuffle    villager-agnes   \n",
      "3   Steep Hill   Ayyeeee       villager-al   \n",
      "4  Forest Life  it'sa me  villager-alfonso   \n",
      "\n",
      "                                                 url  \n",
      "0  https://villagerdb.com/images/villagers/thumb/...  \n",
      "1  https://villagerdb.com/images/villagers/thumb/...  \n",
      "2  https://villagerdb.com/images/villagers/thumb/...  \n",
      "3  https://villagerdb.com/images/villagers/thumb/...  \n",
      "4  https://villagerdb.com/images/villagers/thumb/...  \n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "\n",
    "# View the First Few Rows\n",
    "print(villagers_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "817e50c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            row_n\n",
      "count  391.000000\n",
      "mean   239.902813\n",
      "std    140.702672\n",
      "min      2.000000\n",
      "25%    117.500000\n",
      "50%    240.000000\n",
      "75%    363.500000\n",
      "max    483.000000\n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "\n",
    "# Get the Basic Summary\n",
    "print(villagers_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bcc9eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id     name gender species birthday personality          song  \\\n",
      "count       390      391    391     391      391         391           380   \n",
      "unique      390      391      2      35      361           8            92   \n",
      "top     admiral  Admiral   male     cat     1-27        lazy  K.K. Country   \n",
      "freq          1        1    204      23        2          60            10   \n",
      "\n",
      "         phrase           full_id  \\\n",
      "count       391               391   \n",
      "unique      388               391   \n",
      "top     wee one  villager-admiral   \n",
      "freq          2                 1   \n",
      "\n",
      "                                                      url  \n",
      "count                                                 391  \n",
      "unique                                                391  \n",
      "top     https://villagerdb.com/images/villagers/thumb/...  \n",
      "freq                                                    1  \n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "\n",
    "# Summarize Non-Numeric Columns\n",
    "print(villagers_data.describe(include=['object']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3c11078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_n           0\n",
      "id              1\n",
      "name            0\n",
      "gender          0\n",
      "species         0\n",
      "birthday        0\n",
      "personality     0\n",
      "song           11\n",
      "phrase          0\n",
      "full_id         0\n",
      "url             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "\n",
    "# Check for Missing Data\n",
    "print(villagers_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9b31ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Summary of Numerical Columns:\n",
      "            row_n\n",
      "count  391.000000\n",
      "mean   239.902813\n",
      "std    140.702672\n",
      "min      2.000000\n",
      "25%    117.500000\n",
      "50%    240.000000\n",
      "75%    363.500000\n",
      "max    483.000000\n",
      "\n",
      "Frequency of Each Species:\n",
      "species\n",
      "cat          23\n",
      "rabbit       20\n",
      "frog         18\n",
      "squirrel     18\n",
      "duck         17\n",
      "dog          16\n",
      "cub          16\n",
      "pig          15\n",
      "bear         15\n",
      "mouse        15\n",
      "horse        15\n",
      "bird         13\n",
      "penguin      13\n",
      "sheep        13\n",
      "elephant     11\n",
      "wolf         11\n",
      "ostrich      10\n",
      "deer         10\n",
      "eagle         9\n",
      "gorilla       9\n",
      "chicken       9\n",
      "koala         9\n",
      "goat          8\n",
      "hamster       8\n",
      "kangaroo      8\n",
      "monkey        8\n",
      "anteater      7\n",
      "hippo         7\n",
      "tiger         7\n",
      "alligator     7\n",
      "lion          7\n",
      "bull          6\n",
      "rhino         6\n",
      "cow           4\n",
      "octopus       3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Frequency of Each Personality Type:\n",
      "personality\n",
      "lazy      60\n",
      "normal    59\n",
      "cranky    55\n",
      "snooty    55\n",
      "jock      55\n",
      "peppy     49\n",
      "smug      34\n",
      "uchi      24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "\n",
    "# Get Data Types and Structure\n",
    "print(villagers_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3ecf371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset (rows, columns): (891, 15)\n"
     ]
    }
   ],
   "source": [
    "# Question 4\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the shape of the dataset\n",
    "print(\"Shape of the dataset (rows, columns):\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "360a4d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of numeric columns:\n",
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "# Question 4\n",
    "\n",
    "# Default describe (numeric columns only)\n",
    "print(\"Summary of numeric columns:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "428e9c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of all columns (numeric and non-numeric):\n",
      "          survived      pclass   sex         age       sibsp       parch  \\\n",
      "count   891.000000  891.000000   891  714.000000  891.000000  891.000000   \n",
      "unique         NaN         NaN     2         NaN         NaN         NaN   \n",
      "top            NaN         NaN  male         NaN         NaN         NaN   \n",
      "freq           NaN         NaN   577         NaN         NaN         NaN   \n",
      "mean      0.383838    2.308642   NaN   29.699118    0.523008    0.381594   \n",
      "std       0.486592    0.836071   NaN   14.526497    1.102743    0.806057   \n",
      "min       0.000000    1.000000   NaN    0.420000    0.000000    0.000000   \n",
      "25%       0.000000    2.000000   NaN   20.125000    0.000000    0.000000   \n",
      "50%       0.000000    3.000000   NaN   28.000000    0.000000    0.000000   \n",
      "75%       1.000000    3.000000   NaN   38.000000    1.000000    0.000000   \n",
      "max       1.000000    3.000000   NaN   80.000000    8.000000    6.000000   \n",
      "\n",
      "              fare embarked  class  who adult_male deck  embark_town alive  \\\n",
      "count   891.000000      889    891  891        891  203          889   891   \n",
      "unique         NaN        3      3    3          2    7            3     2   \n",
      "top            NaN        S  Third  man       True    C  Southampton    no   \n",
      "freq           NaN      644    491  537        537   59          644   549   \n",
      "mean     32.204208      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "std      49.693429      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "min       0.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "25%       7.910400      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "50%      14.454200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "75%      31.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "max     512.329200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "\n",
      "       alone  \n",
      "count    891  \n",
      "unique     2  \n",
      "top     True  \n",
      "freq     537  \n",
      "mean     NaN  \n",
      "std      NaN  \n",
      "min      NaN  \n",
      "25%      NaN  \n",
      "50%      NaN  \n",
      "75%      NaN  \n",
      "max      NaN  \n"
     ]
    }
   ],
   "source": [
    "# Question 4\n",
    "\n",
    "# Include all columns in describe\n",
    "print(\"Summary of all columns (numeric and non-numeric):\")\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa7380ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Question 4\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94a93c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4 (Explanation)\n",
    "\n",
    "# Part A (Number of Columns Analyzed)\n",
    "    # df.shape gives you the total number of rows and columns in the dataset as it doesn’t filter between types of data (numeric, categorical, etc.).\n",
    "    # df.describe() only summarizes numeric columns (e.g. age, fare, etc.), so it may analyze fewer columns than what df.shape reports since it doesn't include categorical columns (e.g. sex, embarked)\n",
    "    \n",
    "# Part B (Values Reported in the \"Count\" Column)\n",
    "    # The \"count\" column in df.describe() tells the number of non-missing (non-null) values in each column. It shows how many valid entries there are for each variable. If some rows do have missing values (e.g., NaN), those are excluded from the count.\n",
    "    # However, df.shape shows the total number of rows, regardless it containing missing data or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29a1f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5\n",
    "    # Attributes (Provides stored information)\n",
    "        # Attributes represent stored data of the characteristics or properties of an object\n",
    "        # Accessed without parentheses (e.g., df.shape)\n",
    "        # Simply return information without performing any action or computation\n",
    "        \n",
    "    # Methods (Performs actions on the data)\n",
    "        # Methods present functions that perform specific actions, operations or calculations on an object\n",
    "        # Called with parentheses (e.g., df.describe())\n",
    "        # Execute a process or computation when invoked, potentially modifying or returning new information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328e5f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of Interactions\n",
    "\n",
    "# Dataset Overview (Animal Crossing Villagers):\n",
    "    # You provided a dataset URL related to Animal Crossing villagers and wanted to know the number of rows and columns, along with the column names.\n",
    "    # I helped you with Python code to load the dataset using pandas, check its shape, and view the columns.\n",
    "\n",
    "# Basic Summarization in Python:\n",
    "    # I provided Python snippets to summarize the dataset, including viewing basic descriptive statistics (df.describe()), checking for missing values, and displaying column names and unique values.\n",
    "    # We discussed the simplest summarization techniques, such as using .head(), .describe(), and .info().\n",
    "\n",
    "# Explanation of Dataset Size and df.describe() Discrepancies (Titanic Dataset):\n",
    "    # You wanted to understand the difference between the dataset size (using df.shape) and the values reported by df.describe().\n",
    "    # I explained the discrepancies:\n",
    "        # df.shape shows the total rows and columns.\n",
    "        # df.describe() analyzes only numeric columns by default (fewer columns) and reports the count of non-missing values (which can be less than the total row count).\n",
    "    # I provided code examples to analyze these discrepancies, including checking for missing values using df.isnull().sum().\n",
    "\n",
    "# Difference Between Attributes and Methods:\n",
    "    # We discussed the difference between Python attributes (e.g., df.shape) and methods (e.g., df.describe()):\n",
    "    # Attributes are properties of an object and don’t require parentheses.\n",
    "    # Methods are functions that perform actions and require parentheses.\n",
    "    # I provided a summarized distinction between attributes and methods, along with examples.\n",
    "    \n",
    "# Link: https://chatgpt.com/share/c90b9edf-bc44-4825-b018-84afc281416b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dde66aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST - LECTURE HW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c5efaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6\n",
    "\n",
    "    # Count: The total number of non-null values or enteries in each column, excluding any missing values\n",
    "    # Mean: The average of the values in the column\n",
    "    # Std (Standard Deviation): A measure of the amount of variation or dispersion in the column (tells you how spread out the values are around the mean)\n",
    "    # Min: The minimum value in the column or the smallest value among the non-null entries\n",
    "    # 25% (First Quartile or Q1): The first quartile, the value below which 25% of the data falls\n",
    "    # 50% (Median or Second Quartile or Q2): The middle value of the column, with 50% of the values being below this point and 50% being above it\n",
    "    # 75% (Third Quartile or Q3): The third quartile, the value below which 75% of the data falls\n",
    "    # Max: The maximum value in the column or the largest value among the non-null entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1113dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 7 (Number 1, 2, 3)\n",
    "\n",
    "# Number 1\n",
    "    # If it is need to make sure every row has all the important information, like for a detailed analysis where missing data could affect the quality or completeness of the results, using df.dropna() will remove rows with any missing values.\n",
    "    # Using df.dropna() ensures that each row of data has all the required information, making the analysis more reliable.\n",
    "    \n",
    "# Number 2\n",
    "    # If there is a column with lots of missing values and it’s not important for the analysis, using del df['col'] will help remove that column entirely.\n",
    "    # Removing a column with del df['col'] can simplify datasets and avoid potential issues arising from missing values in less important features.\n",
    "    \n",
    "# Number 3\n",
    "    # If there are columns with a very high proportion of missing data, removing those columns first with del df['col'] can reduce the dataset’s complexity.\n",
    "    # After removing those of less importance, then using df.dropna() can help to focus on rows with missing values in the remaining, more crucial columns. \n",
    "    # This ensures that we are only addressing missing values in columns that matter for the analysis and not wasting time or resources on columns that were going to be discarded anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f2d78bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
      "       'alive', 'alone'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Check column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fab9de54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   survived     891 non-null    int64  \n",
      " 1   pclass       891 non-null    int64  \n",
      " 2   sex          891 non-null    object \n",
      " 3   age          714 non-null    float64\n",
      " 4   sibsp        891 non-null    int64  \n",
      " 5   parch        891 non-null    int64  \n",
      " 6   fare         891 non-null    float64\n",
      " 7   embarked     889 non-null    object \n",
      " 8   class        891 non-null    object \n",
      " 9   who          891 non-null    object \n",
      " 10  adult_male   891 non-null    bool   \n",
      " 11  deck         203 non-null    object \n",
      " 12  embark_town  889 non-null    object \n",
      " 13  alive        891 non-null    object \n",
      " 14  alone        891 non-null    bool   \n",
      "dtypes: bool(2), float64(2), int64(4), object(7)\n",
      "memory usage: 92.4+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 889 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   survived     889 non-null    int64  \n",
      " 1   pclass       889 non-null    int64  \n",
      " 2   sex          889 non-null    object \n",
      " 3   sibsp        889 non-null    int64  \n",
      " 4   parch        889 non-null    int64  \n",
      " 5   fare         889 non-null    float64\n",
      " 6   embarked     889 non-null    object \n",
      " 7   class        889 non-null    object \n",
      " 8   who          889 non-null    object \n",
      " 9   adult_male   889 non-null    bool   \n",
      " 10  embark_town  889 non-null    object \n",
      " 11  alive        889 non-null    object \n",
      " 12  alone        889 non-null    bool   \n",
      "dtypes: bool(2), float64(1), int64(4), object(6)\n",
      "memory usage: 85.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Question 7 (Number 4)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Before cleaning\n",
    "before_cleaning = df.info()\n",
    "\n",
    "# Remove columns with excessive missing values\n",
    "cols_to_drop = ['age', 'deck']\n",
    "df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Drop rows with any remaining missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# After cleaning\n",
    "after_cleaning = df.info()\n",
    "\n",
    "# Results\n",
    "    # Before Cleaning: The dataset might have many columns with missing data.\n",
    "    # After Cleaning: The dataset is simplified with fewer columns and all remaining rows have complete data in the important columns, reducing the dataset's complexity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2234d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of Interactions\n",
    "# 1. Missing Data Handling:\n",
    "    # Definitions of Summary Statistics (from df.describe()):\n",
    "        # Count: Number of non-null entries.\n",
    "        # Mean: Average value.\n",
    "        # Std: Measure of value spread around the mean.\n",
    "        # Min: Lowest value.\n",
    "        # 25%: Value below which 25% of data falls (first quartile).\n",
    "        # 50%: Middle value (median).\n",
    "        # 75%: Value below which 75% of data falls (third quartile).\n",
    "        # Max: Highest value.\n",
    "    # Use Cases for Handling Missing Data:\n",
    "        # Using df.dropna(): Preferable when you need to ensure every row in your analysis has all important information. It removes rows with missing values.\n",
    "        # Using del df['col']: Preferable when a column has a lot of missing values and is not crucial for your analysis. It removes that column entirely.\n",
    "        # Combining del df['col'] and df.dropna(): First removing columns with excessive missing data using del df['col'] simplifies the dataset. Then using df.dropna() to remove rows with missing values in the remaining columns ensures a cleaner dataset.\n",
    "\n",
    "# 2. Practical Application:\n",
    "    # Problem Encountered: An attempt to drop columns from the Titanic dataset resulted in a KeyError, indicating some columns did not exist.\n",
    "    # Solution: Check the actual column names in the DataFrame, update the columns to drop based on the existing names, and then proceed with dropping the rows with any remaining missing values.\n",
    "    # Steps to Fix the Error:\n",
    "        # Load the dataset and print column names.\n",
    "        # Update the list of columns to drop to match the actual column names.\n",
    "        # Drop the columns that exist and then use df.dropna() to clean up the rows.\n",
    "        \n",
    "# Link: https://chatgpt.com/share/6dcc90aa-bab7-459c-b74a-d5765eb4a0eb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b3264d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
      "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
      "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
      "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
      "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
      "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
      "\n",
      "   body_mass_g     sex  \n",
      "0       3750.0    MALE  \n",
      "1       3800.0  FEMALE  \n",
      "2       3250.0  FEMALE  \n",
      "3          NaN     NaN  \n",
      "4       3450.0  FEMALE  \n",
      "           count        mean       std    min    25%    50%    75%    max\n",
      "species                                                                  \n",
      "Adelie     151.0  189.953642  6.539457  172.0  186.0  190.0  195.0  210.0\n",
      "Chinstrap   68.0  195.823529  7.131894  178.0  191.0  196.0  201.0  212.0\n",
      "Gentoo     123.0  217.186992  6.484976  203.0  212.0  216.0  221.0  231.0\n"
     ]
    }
   ],
   "source": [
    "# Question 8, Number 1\n",
    "    # df.groupby(\"col1\")[\"col2\"].describe() will give a detailed statistical summary of \"col2\" for each group defined by unique values in \"col1\"\n",
    "    # Example:\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Group by 'species' and describe the 'flipper_length_mm'\n",
    "summary_stats = df.groupby('species')['flipper_length_mm'].describe()\n",
    "print(summary_stats)\n",
    "\n",
    "    # Explanation:\n",
    "        # df.groupby('species'): Groups the dataset based on each unique species in the species column (e.g., Adelie, Chinstrap, and Gentoo).\n",
    "        # ['flipper_length_mm']: Selects the flipper_length_mm column from each group\n",
    "        # .describe(): Provides summary statistics for flipper_length_mm within each species group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c8b5ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 8, Number 2\n",
    "    # The counts differ because df.describe() is aggregate across the entire dataset, and df.groupby(\"col1\")[\"col2\"].describe() is specific to each group.\n",
    "    # df.describe() provides more of an overall count of non-missing values for each column\n",
    "    # df.groupby(\"col1\")[\"col2\"].describe(), on the other hand, provides group-specific counts of non-missing values for \"col2\" based on unique values in \"col1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4dc3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 8, Number 3\n",
    "    # Personally, I find it much easier to easier to work in a ChatBot session to fix the errors rather than using google to search for and fix errors.\n",
    "    # This is because, ChatGPT or ChatBots in general directly are able to provide me with the solution to my problem rather than having to look up each and every one of the sources provided in Google to find which can help me the most.\n",
    "    # Other than that, ChatBots take much faster and give me the correct answers to the issues and problems I have been having whereas searchin in Google takes me much longer having to look at each and every website to find me the solution to my problem.\n",
    "    # Lastly, ChatBots also provide with the new codes to fix my issue whereas sometimes in the searches I have done on Google, it takes me a while to find one with the codes to fix my issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dfb568e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
      "       'alive', 'alone'],\n",
      "      dtype='object')\n",
      "        count       mean        std   min   25%   50%   75%   max\n",
      "sex                                                              \n",
      "female  261.0  27.915709  14.110146  0.75  18.0  27.0  37.0  63.0\n",
      "male    453.0  30.726645  14.678201  0.42  21.0  29.0  39.0  80.0\n"
     ]
    }
   ],
   "source": [
    "# Summary of Interactions\n",
    "\n",
    "# Initial Inquiry:\n",
    "    # You sought help understanding the df.groupby(\"col1\")[\"col2\"].describe() code in pandas and requested a demonstration using a dataset.\n",
    "\n",
    "# Explanation Provided:\n",
    "    # df.groupby(\"col1\")[\"col2\"].describe() groups the DataFrame by \"col1\", selects \"col2\", and computes summary statistics for \"col2\" within each group.\n",
    "    # Example Provided: A demonstration using the Titanic dataset to group by \"class\" and describe \"age\" was suggested.\n",
    "\n",
    "# Code Issues Encountered:\n",
    "    # NameError: You encountered a NameError due to not importing pandas or using incorrect variable names (DF instead of df).\n",
    "    # HTTPError: An error occurred due to a typo in the URL (.cvs instead of .csv).\n",
    "    # AttributeError: You faced an AttributeError because group_by should be groupby.\n",
    "    # KeyError: This occurred because the column name \"Sex\" did not match the actual column name, which was \"sex\".\n",
    "    # SyntaxError: A missing parenthesis in the URL caused a SyntaxError.\n",
    "    # NameError: Another error due to using column names without quotes.\n",
    "\n",
    "# Corrections and Recommendations:\n",
    "    # Ensure that pandas is imported correctly.\n",
    "    # Use the correct file extension (.csv).\n",
    "    # Use the method groupby instead of group_by.\n",
    "    # Column names should be enclosed in quotes when used in code.\n",
    "    # Verify the exact column names using df.columns.\n",
    "\n",
    "# Final Code Example:\n",
    "    # Provided correct code to load the Titanic dataset, check column names, and use groupby with correct column names:\n",
    "import pandas as pd\n",
    "\n",
    "    # Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "    # Check available columns to confirm names\n",
    "print(df.columns)\n",
    "\n",
    "    # Group by 'sex' and describe 'age'\n",
    "summary = df.groupby(\"sex\")[\"age\"].describe()\n",
    "print(summary)\n",
    "\n",
    "# Link: https://chatgpt.com/share/c7cac91e-e9d8-416c-9ad1-c418a52a89ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc253f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 9 \n",
    "    # Have you reviewed the course wiki-textbook and interacted with a ChatBot (or, if that wasn't sufficient, real people in the course piazza discussion board or TA office hours) to help you understand all the material in the tutorial and lecture that you didn't quite follow when you first saw it?\n",
    "    # Answer: Somewhat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
